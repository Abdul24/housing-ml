{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import(\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    "    GridSearchCV\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import(\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import(\n",
    "    LassoCV,\n",
    "    ElasticNetCV,\n",
    "    LinearRegression\n",
    ")\n",
    "\n",
    "from sklearn.feature_selection import(\n",
    "    VarianceThreshold,\n",
    "    chi2,\n",
    "    SelectKBest,\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import(\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    AdaBoostRegressor\n",
    ")\n",
    "\n",
    "from sklearn.metrics import(\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    explained_variance_score\n",
    ")\n",
    "\n",
    "from scipy.stats import skew\n",
    "\n",
    "import pickle\n",
    "import xgboost\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic dummy variable dataframe\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "train = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)\n",
    "train['GarageYrBlt'].fillna(train['YearBuilt'], inplace=True)\n",
    "train[\"PoolQC\"].fillna(\"None\", inplace=True)\n",
    "train[\"MiscFeature\"].fillna(\"None\", inplace=True)\n",
    "train[\"Alley\"].fillna(\"None\", inplace=True)\n",
    "train[\"MasVnrArea\"].fillna(0, inplace=True)\n",
    "train[\"Fence\"].fillna(\"None\", inplace=True)\n",
    "train[\"FireplaceQu\"].fillna(\"None\", inplace=True)\n",
    "# train[\"TotalSF\"] = train[\"TotalBsmtSF\"] + train[\"1stFlrSF\"] + train[\"2ndFlrSF\"]\n",
    "# train.drop([\"TotalBsmtSF\",\"1stFlrSF\",\"2ndFlrSF\"], axis=1, inplace=True)\n",
    "train['Electrical'] = train['Electrical'].fillna(train['Electrical'].mode()[0])\n",
    "train['KitchenQual'] = train['KitchenQual'].fillna(train['KitchenQual'].mode()[0])\n",
    "train['Exterior1st'] = train['Exterior1st'].fillna(train['Exterior1st'].mode()[0])\n",
    "train['Exterior2nd'] = train['Exterior2nd'].fillna(train['Exterior2nd'].mode()[0])\n",
    "train['SaleType'] = train['SaleType'].fillna(train['SaleType'].mode()[0])\n",
    "\n",
    "train[\"LotFrontage\"] = train.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n",
    "    train[col] = train[col].fillna('None') \n",
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    train[col] = train[col].fillna(0)\n",
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    train[col] = train[col].fillna('None')\n",
    "train[\"Functional\"] = train[\"Functional\"].fillna(\"Typ\")\n",
    "train.drop(['Utilities'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "def categorize(df):\n",
    "    df['MSSubClass'] = df['MSSubClass'].astype(\"str\")\n",
    "    df['OverallCond'] = df['OverallCond'].astype(\"str\")\n",
    "    df['YrSold'] = df['YrSold'].astype(\"str\")\n",
    "    df['MoSold'] = df['MoSold'].astype(\"str\")\n",
    "    df[\"OverallQual\"] = df['OverallQual'].astype(\"str\")\n",
    "\n",
    "    return df\n",
    "\n",
    "train = categorize(train)\n",
    "numeric_feats = train.dtypes[train.dtypes != \"object\"].index\n",
    "\n",
    "# Applying logarithmic transform to skewed features\n",
    "# This code was pulled from Alexandru Papiu:\n",
    "# https://www.kaggle.com/apapiu/regularized-linear-models\n",
    "\n",
    "skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "skewed_feats = skewed_feats.index\n",
    "train[skewed_feats] = np.log1p(train[skewed_feats])\n",
    "\n",
    "# Getting dummy variables\n",
    "train_dummies = pd.get_dummies(train)\n",
    "train_dummies = train_dummies.fillna(0)\n",
    "train_dummies = train_dummies[train_dummies.columns[~train_dummies.columns.str.contains('_None')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Full dataframe into Train-test Split\n",
    "def full_set_split(df):\n",
    "    X = df.drop([\"SalePrice\",\"Id\"], axis=1)\n",
    "#     X = vif_filter(X, thresh=5)\n",
    "    y = df[\"SalePrice\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    return (X_train, X_test, y_train, y_test)\n",
    "X_train, X_test, y_train, y_test = full_set_split(train_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def get_models():\n",
    "    \"\"\"Generate a library of base learners.\"\"\"\n",
    "    lm = LinearRegression()\n",
    "    lasso = model_lasso = LassoCV(normalize=True, cv=6)\n",
    "    elastic_net = ElasticNetCV(alphas=[.001])\n",
    "    gbm = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.085,\n",
    "                                       max_depth=2, max_features=10,loss=\"huber\")\n",
    "    rf_5 = RandomForestRegressor(n_estimators=500)\n",
    "#     ada = AdaBoostRegressor(base_estimator=rf)\n",
    "    models = {'Lasso': lasso,\n",
    "              \"Linear\": lm,\n",
    "              'ElasticNet': elastic_net,\n",
    "              'GradientBoost': gbm,\n",
    "              'RandomForest5': rf_5,\n",
    "#               'RandomForest1': rf1,\n",
    "#               'RandomForest2': rf2,\n",
    "#               'AdaBoost': ada\n",
    "              }\n",
    "    return models\n",
    "\n",
    "\n",
    "def train_predict(model_list):\n",
    "    \"\"\"Fit models in list on training set and return preds\"\"\"\n",
    "    P = np.zeros((y_test.shape[0], len(model_list)))\n",
    "    P = pd.DataFrame(P)\n",
    "\n",
    "    print(\"Fitting models.\")\n",
    "    cols = list()\n",
    "    for i, (name, m) in enumerate(models.items()):\n",
    "        print(\"%s...\" % name, end=\" \", flush=False)\n",
    "        m.fit(X_train, y_train)\n",
    "        P.iloc[:, i] = m.predict(X_test)#[:, 1]\n",
    "        cols.append(name)\n",
    "        print(\"done\")\n",
    "\n",
    "    P.columns = cols\n",
    "    print(\"Done.\\n\")\n",
    "    return P\n",
    "\n",
    "\n",
    "def rmse_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)\n",
    "\n",
    "def score_models(P, y):\n",
    "    \"\"\"Score model in prediction DF\"\"\"\n",
    "    print(\"Scoring models.\")\n",
    "    for k,v in models.items():\n",
    "        print(k)\n",
    "        print(rmse_cv(v).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = get_models()\n",
    "# P = train_predict(models)\n",
    "# score_models(P, y_test)\n",
    "# P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_base_learners(base_learners, inp, out):\n",
    "    \"\"\"Train all base learners in the library.\"\"\"\n",
    "    print(\"Fitting models.\")\n",
    "    for i, (name, m) in enumerate(base_learners.items()):\n",
    "        print(\"%s...\" % name, end=\" \", flush=False)\n",
    "        m.fit(inp, out)\n",
    "        print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_base_learners(pred_base_learners, inp):\n",
    "    \"\"\"Generate a prediction matrix.\"\"\"\n",
    "    P = np.zeros((inp.shape[0], len(pred_base_learners)))\n",
    "    print(\"Generating base learner predictions.\")\n",
    "    for i, (name, m) in enumerate(pred_base_learners.items()):\n",
    "        print(\"%s...\" % name, end=\" \", flush=False)\n",
    "        p = m.predict(inp)\n",
    "        P[:, i] = p\n",
    "        print(\"done\")\n",
    "\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensemble_predict(base_learners, meta_learner, inp):\n",
    "    \"\"\"Generate predictions from the ensemble.\"\"\"\n",
    "    P_pred = predict_base_learners(base_learners, inp)\n",
    "    return P_pred, meta_learner.predict(P_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_pred, p = ensemble_predict(base_learners, meta_learner, xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "def stacking(base_learners, meta_learner, X, y, generator):\n",
    "    \"\"\"Simple training routine for stacking.\"\"\"\n",
    "\n",
    "    # Train final base learners for test time\n",
    "    print(\"Fitting final base learners...\", end=\"\")\n",
    "    train_base_learners(base_learners, X, y)\n",
    "    print(\"done\")\n",
    "\n",
    "    # Generate predictions for training meta learners\n",
    "    # Outer loop:\n",
    "    print(\"Generating cross-validated predictions...\")\n",
    "    cv_preds, cv_y = [], []\n",
    "    for i, (train_idx, test_idx) in enumerate(generator.split(X)):\n",
    "\n",
    "        fold_xtrain, fold_ytrain = X[train_idx, :], y[train_idx]\n",
    "        fold_xtest, fold_ytest = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        # Inner loop: step 4 and 5\n",
    "        fold_base_learners = {name: clone(model)\n",
    "                              for name, model in base_learners.items()}\n",
    "        train_base_learners(\n",
    "            fold_base_learners, fold_xtrain, fold_ytrain)\n",
    "\n",
    "        fold_P_base = predict_base_learners(\n",
    "            fold_base_learners, fold_xtest)\n",
    "\n",
    "        cv_preds.append(fold_P_base)\n",
    "        cv_y.append(fold_ytest)\n",
    "        print(\"Fold %i done\" % (i + 1))\n",
    "\n",
    "    print(\"CV-predictions done\")\n",
    "    \n",
    "    # Be careful to get rows in the right order\n",
    "    cv_preds = np.vstack(cv_preds)\n",
    "    cv_y = np.hstack(cv_y)\n",
    "#     print(cv_preds.shape)\n",
    "#     print(len(cv_y))\n",
    "    # Train meta learner\n",
    "    print(\"Fitting meta learner...\", end=\"\")\n",
    "    meta_learner.fit(cv_preds, cv_y)\n",
    "    print(\"done\")\n",
    "\n",
    "    return base_learners, meta_learner,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_learner = GradientBoostingRegressor(n_estimators=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting final base learners...Fitting models.\n",
      "Lasso... done\n",
      "Linear... done\n",
      "ElasticNet... done\n",
      "GradientBoost... done\n",
      "RandomForest5... done\n",
      "done\n",
      "Generating cross-validated predictions...\n",
      "Fitting models.\n",
      "Lasso... done\n",
      "Linear... done\n",
      "ElasticNet... done\n",
      "GradientBoost... done\n",
      "RandomForest5... done\n",
      "Generating base learner predictions.\n",
      "Lasso... done\n",
      "Linear... done\n",
      "ElasticNet... done\n",
      "GradientBoost... done\n",
      "RandomForest5... done\n",
      "Fold 1 done\n",
      "Fitting models.\n",
      "Lasso... done\n",
      "Linear... done\n",
      "ElasticNet... done\n",
      "GradientBoost... done\n",
      "RandomForest5... done\n",
      "Generating base learner predictions.\n",
      "Lasso... done\n",
      "Linear... done\n",
      "ElasticNet... done\n",
      "GradientBoost... done\n",
      "RandomForest5... done\n",
      "Fold 2 done\n",
      "Fitting models.\n",
      "Lasso... done\n",
      "Linear... done\n",
      "ElasticNet... done\n",
      "GradientBoost... done\n",
      "RandomForest5... done\n",
      "Generating base learner predictions.\n",
      "Lasso... done\n",
      "Linear... done\n",
      "ElasticNet... done\n",
      "GradientBoost... done\n",
      "RandomForest5... done\n",
      "Fold 3 done\n",
      "CV-predictions done\n",
      "Fitting meta learner...done\n",
      "Generating base learner predictions.\n",
      "Lasso... done\n",
      "Linear... done\n",
      "ElasticNet... done\n",
      "GradientBoost... done\n",
      "RandomForest5... done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Train with stacking\n",
    "cv_base_learners, cv_meta_learner = stacking(\n",
    "    get_models(), clone(meta_learner), X_train.values, y_train.values, KFold(3))\n",
    "\n",
    "P_pred, p = ensemble_predict(cv_base_learners, cv_meta_learner, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14501375363992536\n"
     ]
    }
   ],
   "source": [
    "def rmse_cv_stack(model, X, y):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv = 10))\n",
    "    return(rmse)\n",
    "print(rmse_cv_stack(cv_meta_learner, P_pred, y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
